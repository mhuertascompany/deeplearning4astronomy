{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from math import log10\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imresize\n",
    "from scipy import misc\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "import glob\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import rmsprop\n",
    "\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_thumb(im,x,y,size):\n",
    "    if size %2==0:\n",
    "        size = size+1\n",
    "    up_x=int(x-size/2)\n",
    "    dow_x=int(x+size/2)\n",
    "    up_y=int(y-size/2)\n",
    "    dow_y=int(y+size/2)\n",
    "    res=im[up_x:dow_x,up_y:dow_y]        \n",
    "    return res \n",
    "\n",
    "# to read data\n",
    "def read_data(pathin,pathsave,maxim):\n",
    "    size_im=69\n",
    "    size_crop=207\n",
    "  \n",
    "\n",
    "    data=fits.getdata(pathin+'Nair_Abraham_cat.fit',1)\n",
    "    idcat=data['dr7objid']\n",
    "    ttype=data['TType']\n",
    "    \n",
    "    #define the morphologies we want to retrieve\n",
    "    m=ttype*0-1\n",
    "    #m[np.where((ttype>=0) & ((ttype<=3)))]=1\n",
    "    #m[np.where(((ttype<0) & (ttype>=-5)) | ((ttype>3) & (ttype<=10)))]=0\n",
    "    m[np.where((ttype>=-5) & (ttype<=0))]=0\n",
    "    m[np.where((ttype>0) & (ttype<=10))]=1\n",
    "      \n",
    "    D=np.zeros([maxim,size_im,size_im,3])  #input tensor - images dimensions + color channels\n",
    "    Y=np.zeros(maxim) #label vector\n",
    "    idvec=np.zeros([maxim], dtype=np.long)\n",
    "    \n",
    "    iteri=-1;\n",
    "    numim=0;\n",
    "    numim_init=numim\n",
    "    nplace=0  #location 1st galaxy to be read \n",
    "    catalog=Table(data)\n",
    "\n",
    "    while iteri<maxim-1:\n",
    "        try:\n",
    "            numgal=idcat[numim]\n",
    "            namegal=str(numgal)+\"_GZOO_.jpg\"        \n",
    "            scidata = misc.imread(pathin+'/cutouts_jpeg_all/'+namegal)\n",
    "            f=numim\n",
    "            \n",
    "            print('reading: '+namegal)\n",
    "            \n",
    "        except:\n",
    "            print(\"Galaxy number %d is missing\" % (numim))\n",
    "            print(namegal)\n",
    "            numim += 1\n",
    "            continue\n",
    "        \n",
    "        lx,ly, lz=scidata.shape\n",
    "        #wrong shape - ignore image\n",
    "        if lx < 256 or ly<256 or m[f]<0:\n",
    "            numim += 1\n",
    "            continue\n",
    "\n",
    "        if lx<size_im:\n",
    "            numim += 1\n",
    "            continue\n",
    "\n",
    "        \n",
    "        scidata = extract_thumb(scidata,int(lx/2.0),int(ly/2.0),size_crop) # take only a cutout of 207*207 pixels\n",
    "        scidata=zoom(scidata, [1/3.,1./3,1], order=3)  #keep 1/3 pixels to speed up\n",
    "        \n",
    "        \n",
    "        iteri=iteri+1\n",
    "        \n",
    "        #scidata = np.transpose(scidata) #tranpose image\n",
    "        \n",
    "        D[iteri,:,:,:]=scidata  #add image to the input tensor\n",
    "\n",
    "        Y[iteri]=m[f] #update the label\n",
    "        \n",
    "        idvec[iteri]=idcat[f] \n",
    "\n",
    "        if iteri%100 ==0:\n",
    "            print(\"Saving example\")\n",
    "            misc.imsave(pathsave+\"examples_stamps/\"+namegal,scidata)\n",
    "            \n",
    "         \n",
    "        numim=numim+1\n",
    "\n",
    "        \n",
    "        Y = Y.squeeze()\n",
    "\n",
    "    # this is to avoid reading all images at every training\n",
    "    print(\"Saving image and target vector\")\n",
    "    np.save(pathsave+\"image_vector_Sab_\"+str(maxim)+\".npy\",D) \n",
    "    np.save(pathsave+\"target_vector_Sab_\"+str(maxim)+\".npy\",Y)\n",
    "    np.save(pathsave+\"ID_vector_Sab_\"+str(maxim)+\".npy\",idvec) \n",
    "\n",
    "    return D,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only two convolutional layers - this can be changed\n",
    "\n",
    "def CNN_Nair(img_channels, img_rows, img_cols):\n",
    "    dropoutpar=0.5\n",
    "    depth=16 #32   \n",
    "    nb_dense = 64\n",
    "    # SGD parameters [when using SGD optimizer]\n",
    "    #lr=0.001   #0.001\n",
    "    #decay=0\n",
    "    #momentum=0.9   #0.9\n",
    "    #nesterov=True\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(depth, 3, 3,init='orthogonal',activation='relu',border_mode='same', input_shape=( img_rows, img_cols,img_channels)))\n",
    "    model.add(Dropout(dropoutpar))\n",
    "    model.add(Convolution2D(depth*2, 5, 5,init='orthogonal',activation='relu',border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_dense, activation='relu'))\n",
    "    model.add(Dropout(dropoutpar)) \n",
    "    model.add(Dense(1, init='uniform', activation='softmax'))\n",
    "    print(\"Compilation...\")\n",
    "    #sgd = SGD(lr=lr, decay=decay, momentum=momentum, nesterov=True) #uncomment to use sgd\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    print(\"... done!\")\n",
    "    print(\"Model Summary\")\n",
    "    print(\"===================\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_convnet_Nair(X,Y,ntrain,nval,test_name):\n",
    "\n",
    "\n",
    "        \n",
    "    # train params - hardocded for simplicity\n",
    "    batch_size = 30 #64\n",
    "    nb_epoch = 50\n",
    "    data_augmentation = True\n",
    "    \n",
    "    \n",
    "    ind=random.sample(range(0, ntrain+nval-1), ntrain+nval-1)\n",
    "    X_train = X[ind[0:ntrain],:,:,:]   \n",
    "    X_val = X[ind[ntrain:ntrain+nval],:,:,:]\n",
    "    Y_train = Y[ind[0:ntrain]]\n",
    "    Y_val = Y[ind[ntrain:ntrain+nval]]\n",
    "\n",
    "   \n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = X_train.shape[1:3]\n",
    "    img_channels = 3\n",
    "\n",
    "    print(img_rows,img_cols)\n",
    "    pdb.set_trace()\n",
    "    \n",
    "    ### Right shape for X\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols,img_channels)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols,img_channels)\n",
    "\n",
    "\n",
    "    #Avoid more iterations once convergence\n",
    "    patience_par=10\n",
    "    earlystopping = EarlyStopping( monitor='val_loss',patience = patience_par,verbose=0,mode='auto' )\n",
    "    modelcheckpoint = ModelCheckpoint(test_name+\"_best.hd5\",monitor='val_loss',verbose=0,save_best_only=True)\n",
    "\n",
    "\n",
    "    #build model\n",
    "    model=CNN_Nair(img_channels, img_rows, img_cols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        history = model.fit(X_train, Y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            shuffle=True,\n",
    "                            verbose=verbose, callbacks=[earlystopping, modelcheckpoint])\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "\n",
    "        # this will do preprocessing and realtime data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False, \n",
    "            samplewise_center=False, \n",
    "            featurewise_std_normalization=False, \n",
    "            samplewise_std_normalization=False,\n",
    "            zca_whitening=False, \n",
    "            rotation_range=45,\n",
    "            width_shift_range=0.05,  \n",
    "            height_shift_range=0.05, \n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            zoom_range=[0.75,1.3])  \n",
    "\n",
    "        \n",
    "        datagen.fit(X_train)\n",
    "        \n",
    "        history = model.fit_generator(\n",
    "                    datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                    samples_per_epoch=X_train.shape[0],\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    callbacks=[ earlystopping, modelcheckpoint]\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Saving model...\")\n",
    "    # save weights\n",
    "    model.save_weights(test_name,overwrite=True)\n",
    "    \n",
    "        \n",
    "    \n",
    "    return test_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_convnet_Nair(X,model_name):\n",
    "    \n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = X.shape[1:3]\n",
    "    img_channels = 3\n",
    "    X = X.reshape(X.shape[0], img_rows, img_cols,img_channels)\n",
    "    \n",
    "    #====== load model & predict=======\n",
    "\n",
    "    print(\"Loading weights\", model_name)\n",
    "    \n",
    "    model=CNN_Nair(img_channels, img_rows, img_cols)\n",
    "    model.load_weights(model_name)\n",
    "    Y_pred = model.predict_proba(X)\n",
    "\n",
    "\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images\n",
      "====================\n",
      "reading: 587748927626149924_GZOO_.jpg\n",
      "Saving example\n",
      "reading: 587748927626870899_GZOO_.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:42: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:80: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: 587748927627722875_GZOO_.jpg\n",
      "reading: 587722981742084144_GZOO_.jpg\n",
      "reading: 587722981744640177_GZOO_.jpg\n",
      "reading: 587722981744771128_GZOO_.jpg\n",
      "reading: 587722981745295552_GZOO_.jpg\n",
      "reading: 587722981745426489_GZOO_.jpg\n",
      "reading: 587722981747392587_GZOO_.jpg\n",
      "reading: 587722981748048006_GZOO_.jpg\n",
      "reading: 587722981750276247_GZOO_.jpg\n",
      "reading: 587722981750931635_GZOO_.jpg\n",
      "reading: 587722981754011901_GZOO_.jpg\n",
      "reading: 587722981755977976_GZOO_.jpg\n",
      "reading: 587748928160530448_GZOO_.jpg\n",
      "reading: 587748928160858191_GZOO_.jpg\n",
      "reading: 587748928162562264_GZOO_.jpg\n",
      "reading: 587748928166428807_GZOO_.jpg\n",
      "reading: 587722982278496424_GZOO_.jpg\n",
      "reading: 587722982278758580_GZOO_.jpg\n",
      "reading: 587722982278889623_GZOO_.jpg\n",
      "reading: 587722982282035411_GZOO_.jpg\n",
      "reading: 587722982283214886_GZOO_.jpg\n",
      "reading: 587722982284460121_GZOO_.jpg\n",
      "reading: 587722982284460272_GZOO_.jpg\n",
      "reading: 587722982284525580_GZOO_.jpg\n",
      "reading: 587722982285967469_GZOO_.jpg\n",
      "reading: 587722982289834254_GZOO_.jpg\n",
      "reading: 587722982290620479_GZOO_.jpg\n",
      "reading: 587722982290686153_GZOO_.jpg\n",
      "reading: 587722982290948308_GZOO_.jpg\n",
      "reading: 587722982291210350_GZOO_.jpg\n",
      "reading: 587722982291407103_GZOO_.jpg\n",
      "reading: 587722982291734550_GZOO_.jpg\n",
      "reading: 587722982291865751_GZOO_.jpg\n",
      "reading: 587722982292455684_GZOO_.jpg\n",
      "reading: 587722982292717776_GZOO_.jpg\n",
      "reading: 587722982297305365_GZOO_.jpg\n",
      "reading: 587722982297698635_GZOO_.jpg\n",
      "reading: 587722982298615914_GZOO_.jpg\n",
      "reading: 587722982298616131_GZOO_.jpg\n",
      "reading: 587722982299402394_GZOO_.jpg\n",
      "reading: 587722982299992357_GZOO_.jpg\n",
      "reading: 587722982300516593_GZOO_.jpg\n",
      "reading: 587748928697860108_GZOO_.jpg\n",
      "reading: 587748928699301981_GZOO_.jpg\n",
      "reading: 587722982814122096_GZOO_.jpg\n",
      "reading: 587722982814318600_GZOO_.jpg\n",
      "reading: 587722982815760526_GZOO_.jpg\n",
      "reading: 587722982815891459_GZOO_.jpg\n",
      "reading: 587722982817529962_GZOO_.jpg\n",
      "Saving image and target vector\n"
     ]
    }
   ],
   "source": [
    "READ_IMAGES=True\n",
    "LOAD_NPY=False\n",
    "\n",
    "\n",
    "maxim=50  #number of images to read in D, Y vectors\n",
    "\n",
    "pathin=\"/Users/marchuertascompany/Documents/teaching/big_data_ED/morphology/\"\n",
    "pathsave = \"/Users/marchuertascompany/Documents/teaching/big_data_ED/morphology/Sab/\"\n",
    "nparams=1\n",
    "\n",
    "#file to save model weights\n",
    "model_name=pathsave+\"Nair_Sab.hd5\"\n",
    "\n",
    "## reading\n",
    "\n",
    "if READ_IMAGES:\n",
    "    print(\"Reading images\")\n",
    "    print(\"====================\")\n",
    "    D,Y=read_data(pathin,pathsave,maxim)  #read images\n",
    "    \n",
    "if LOAD_NPY:\n",
    "    print(\"Loading D, Y\")\n",
    "    D=np.load(pathsave+\"image_vector_TType_\"+str(maxim)+\".npy\")\n",
    "    Y=np.load(pathsave+\"target_vector_TType_\"+str(maxim)+\".npy\")\n",
    "    ID=np.load(pathsave+\"ID_vector_TType_\"+str(maxim)+\".npy\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "====================\n",
      "69 69\n",
      "> <ipython-input-8-bbbe2b32a78e>(26)train_convnet_Nair()\n",
      "-> X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols,img_channels)\n",
      "(Pdb) c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(69, 69, 3..., padding=\"same\", kernel_initializer=\"orthogonal\")`\n",
      "  \n",
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")`\n",
      "  app.launch_new_instance()\n",
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"softmax\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation...\n",
      "... done!\n",
      "Model Summary\n",
      "===================\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 69, 69, 16)        448       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 69, 69, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 69, 69, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 34, 34, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36992)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2367552   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,380,897\n",
      "Trainable params: 2,380,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1, epochs=50)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.9084 - acc: 0.5667 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 11.1597 - acc: 0.3000 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.8455 - acc: 0.6333 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.9084 - acc: 0.5667 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.9084 - acc: 0.5667 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 7.4398 - acc: 0.5333 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 6.3770 - acc: 0.6000 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.9084 - acc: 0.5667 - val_loss: 5.3141 - val_acc: 0.6667\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "ntrain=int(D.shape[0]*8/10)\n",
    "nval=int(ntrain/10)    \n",
    "D, Y, = shuffle(D,Y,random_state=0)  #change order so that we do not use always the same objects to train/test\n",
    "\n",
    "\n",
    "print(\"Training Model\")\n",
    "print(\"====================\")\n",
    "model_name=train_convnet_Nair(D,Y,ntrain,nval,model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating model\n",
      "====================\n",
      "Loading weights /Users/marchuertascompany/Documents/teaching/big_data_ED/morphology/Sab/Nair_Sab.hd5\n",
      "Compilation...\n",
      "... done!\n",
      "Model Summary\n",
      "===================\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 69, 69, 16)        448       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 69, 69, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 69, 69, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 34, 34, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 36992)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2367552   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,380,897\n",
      "Trainable params: 2,380,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(69, 69, 3..., padding=\"same\", kernel_initializer=\"orthogonal\")`\n",
      "  \n",
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), activation=\"relu\", padding=\"same\", kernel_initializer=\"orthogonal\")`\n",
      "  app.launch_new_instance()\n",
      "/Users/marchuertascompany/anaconda3/envs/astrophd_tutorial/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"softmax\", kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "npred=D.shape[0]-(ntrain+nval)  #test sample size; \n",
    "pred_index=ntrain+nval          #test sample start index ;\n",
    "\n",
    "\n",
    "print(\"Validating model\")\n",
    "print(\"====================\")\n",
    "Y_pred=test_convnet_Nair(D[pred_index:pred_index+npred,:,:,:],model_name) \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
